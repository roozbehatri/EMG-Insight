{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7700486f-5d71-45f3-bd23-d200ad6ce4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import butter, filtfilt, welch\n",
    "\n",
    "# --- folder layout ---\n",
    "ROOT = Path(\"..\")  # notebook lives in notebooks/\n",
    "DATA_RAW = ROOT / \"data/ninapro/db1/raw\"\n",
    "DATA_PROCESSED = ROOT / \"data/processed/db1\"\n",
    "DATA_OUTPUTS = ROOT / \"data/outputs/db1\"\n",
    "MODELS_DIR = ROOT / \"models/db1\"\n",
    "REPORTS_DIR = ROOT / \"reports/db1\"\n",
    "\n",
    "# make dirs that will receive outputs\n",
    "for p in [DATA_PROCESSED, DATA_OUTPUTS, MODELS_DIR, REPORTS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FS = 100.0  # DB1 sampling (RMS)\n",
    "WINDOW_S, STEP_S = 0.2, 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6efbe9b7-d508-4c9f-a1ae-5fad2355727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_nonmeta_keys(d):\n",
    "    \"\"\"\n",
    "    Convert all keys of a MATLAB-loaded dict to lowercase,\n",
    "    while ignoring MATLAB metadata keys (those starting with '__').\n",
    "\n",
    "    Example:\n",
    "        {'EMG': ..., '__header__': ...} \n",
    "        -> {'emg': ...}\n",
    "    \"\"\"\n",
    "    return {k.lower(): v for k, v in d.items() if not k.startswith(\"__\")}\n",
    "\n",
    "\n",
    "def pick_key(d, name, required=True):\n",
    "    \"\"\"\n",
    "    Retrieve a key from dictionary `d` in a case-insensitive way.\n",
    "    \n",
    "    - `name`: the key we want (case-insensitive).\n",
    "    - If not found and `required=True`, raise KeyError.\n",
    "    - If not found and `required=False`, return None.\n",
    "    \n",
    "    This is useful because MATLAB .mat keys may vary in case (\"emg\" vs \"EMG\").\n",
    "    \"\"\"\n",
    "    name = name.lower()\n",
    "    if name in d:\n",
    "        return d[name]\n",
    "    for k in d.keys():\n",
    "        if k.lower() == name:\n",
    "            return d[k]\n",
    "    if required:\n",
    "        raise KeyError(f\"Key '{name}' not in keys: {list(d.keys())}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def read_mat(path): \n",
    "    \"\"\"\n",
    "    Load a MATLAB .mat file into a Python dictionary.\n",
    "    \n",
    "    - Uses `scipy.io.loadmat`.\n",
    "    - Converts struct-like objects to normal records (struct_as_record=False).\n",
    "    - Removes MATLAB metadata keys and lowercases the rest.\n",
    "    \"\"\"\n",
    "    from scipy.io import loadmat\n",
    "    return lower_nonmeta_keys(loadmat(path, squeeze_me=True, struct_as_record=False))\n",
    "\n",
    "\n",
    "def ensure_samples_channels(X):\n",
    "    \"\"\"\n",
    "    Ensure that EMG data has the shape (samples, channels).\n",
    "    \n",
    "    - Converts 1D array into column vector.\n",
    "    - If array shape looks transposed (more channels than samples), transpose it.\n",
    "    - Always returns float32 for ML consistency.\n",
    "    \n",
    "    Example:\n",
    "        Input shape: (10,)         -> Output shape: (10, 1)\n",
    "        Input shape: (32, 2000)    -> Output shape: (2000, 32)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    if X.ndim == 1:       # make sure we always have 2D\n",
    "        X = X[:, None]\n",
    "    if X.shape[0] < X.shape[1] and X.shape[1] > 32:\n",
    "        # Heuristic: if rows < cols and cols > 32 (likely #samples),\n",
    "        # then transpose (so rows = samples, cols = channels).\n",
    "        X = X.T\n",
    "    return X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f504d189-7462-4a9e-b432-0d1710d63c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(x, fs, low=1.0, high=40.0, order=4):\n",
    "    \"\"\"\n",
    "    Apply a Butterworth bandpass filter to EMG data.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): Input signal of shape (samples, channels).\n",
    "        fs (float): Sampling rate in Hz.\n",
    "        low (float): Low cutoff frequency in Hz (default 1 Hz).\n",
    "        high (float): High cutoff frequency in Hz (default 40 Hz).\n",
    "        order (int): Filter order (default 4).\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: Filtered signal with the same shape as x.\n",
    "\n",
    "    Notes:\n",
    "        - EMG signals often contain low-frequency drift (<1 Hz) and\n",
    "          high-frequency noise (>40 Hz).\n",
    "        - Bandpass keeps the physiologically relevant range (1â€“40 Hz here).\n",
    "    \"\"\"\n",
    "    nyq = fs / 2\n",
    "    high = min(high, 0.9 * nyq)  # prevent cutoff above Nyquist\n",
    "    low = max(low, 0.1)          # ensure low > 0\n",
    "    b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n",
    "    return filtfilt(b, a, x, axis=0)  # zero-phase filter (no lag)\n",
    "\n",
    "\n",
    "def rectify_and_zscore(x, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Rectify (absolute value) and standardize EMG signals.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): Input signal (samples, channels).\n",
    "        eps (float): Small constant to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Rectified and z-scored signal.\n",
    "    \n",
    "    Notes:\n",
    "        - Rectification: EMG signals oscillate around zero. \n",
    "          Taking abs(x) makes all values positive, aligning with\n",
    "          muscle activity amplitude.\n",
    "        - Z-score normalization: Each channel is standardized\n",
    "          (mean=0, std=1) to make channels comparable.\n",
    "    \"\"\"\n",
    "    xr = np.abs(x)  \n",
    "    m = xr.mean(0, keepdims=True)       # mean per channel\n",
    "    s = xr.std(0, keepdims=True) + eps  # std per channel\n",
    "    return (xr - m) / s\n",
    "\n",
    "\n",
    "def sliding_window(x, y, window_s=WINDOW_S, step_s=STEP_S, fs=FS):\n",
    "    \"\"\"\n",
    "    Segment EMG signals into overlapping sliding windows.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): Preprocessed EMG data (samples, channels).\n",
    "        y (ndarray): Corresponding label sequence (samples,).\n",
    "        window_s (float): Window length in seconds.\n",
    "        step_s (float): Step size in seconds.\n",
    "        fs (float): Sampling rate.\n",
    "\n",
    "    Returns:\n",
    "        Xw (ndarray): Segments of shape (n_windows, win_len, n_channels).\n",
    "        Yw (ndarray): Window labels (majority / dominant label per window).\n",
    "\n",
    "    Notes:\n",
    "        - Iterates through EMG in steps (step_s), extracting fixed windows (window_s).\n",
    "        - Labels per window: determined by majority vote, with preference for non-zero labels.\n",
    "        - Produces sequences suitable for ML classifiers.\n",
    "    \"\"\"\n",
    "    win, step = int(window_s * fs), int(step_s * fs)\n",
    "    Xw, Yw = [], []\n",
    "    for start in range(0, len(x) - win + 1, step):\n",
    "        seg = x[start:start + win]\n",
    "        lab = y[start:start + win]\n",
    "\n",
    "        # majority label (ignore label 0 if possible)\n",
    "        vals, counts = np.unique(lab, return_counts=True)\n",
    "        idx = counts.argsort()[::-1]\n",
    "        chosen = 0\n",
    "        for j in idx:\n",
    "            if vals[j] != 0: \n",
    "                chosen = vals[j]\n",
    "                break\n",
    "\n",
    "        Xw.append(seg)\n",
    "        Yw.append(chosen)\n",
    "\n",
    "    # stack into arrays\n",
    "    Xw = np.stack(Xw) if Xw else np.empty((0, win, x.shape[1]), dtype=np.float32)\n",
    "    Yw = np.array(Yw, dtype=np.int32)\n",
    "    return Xw, Yw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ceeb42-5dd5-424e-b18e-d871d8ff79bd",
   "metadata": {},
   "source": [
    "# Time-Domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f548a96-7829-4ac4-b1ee-1af4327dc1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(x, axis=0):\n",
    "    \"\"\"Root Mean Square: reflects EMG signal power (muscle contraction intensity).\"\"\"\n",
    "    return np.sqrt((x**2).mean(axis=axis))\n",
    "\n",
    "def mav(x, axis=0):\n",
    "    \"\"\"Mean Absolute Value: average rectified value, proportional to muscle effort.\"\"\"\n",
    "    return np.abs(x).mean(axis=axis)\n",
    "\n",
    "def wl(x, axis=0):\n",
    "    \"\"\"Waveform Length: cumulative length of signal waveform, related to signal complexity.\"\"\"\n",
    "    return np.sum(np.abs(np.diff(x, axis=axis)), axis=axis)\n",
    "\n",
    "def zc(x, axis=0, thresh=0.01):\n",
    "    \"\"\"\n",
    "    Zero Crossings: counts how many times the signal changes sign\n",
    "    (above threshold to avoid noise).\n",
    "    \"\"\"\n",
    "    ch = x if axis == 0 else np.swapaxes(x, 0, axis)\n",
    "    s  = np.sign(ch)\n",
    "    d  = np.diff(ch, axis=0)\n",
    "\n",
    "    # sign change between consecutive samples\n",
    "    sign_change = (s[1:] * s[:-1]) < 0\n",
    "    # amplitude difference check\n",
    "    above_thresh = np.abs(d) > thresh\n",
    "\n",
    "    crossings = sign_change & above_thresh\n",
    "    return crossings.sum(axis=0)\n",
    "\n",
    "def ssc(x, axis=0, thresh=0.01):\n",
    "    \"\"\"\n",
    "    Slope Sign Changes: counts how many times slope changes direction\n",
    "    (above threshold). Captures signal complexity and frequency.\n",
    "    \"\"\"\n",
    "    ch = x if axis == 0 else np.swapaxes(x, 0, axis)\n",
    "    d1 = np.diff(ch, axis=0)\n",
    "\n",
    "    # slope sign change\n",
    "    sign_change = (d1[1:] * d1[:-1]) < 0\n",
    "    # magnitude check\n",
    "    above_thresh = (np.abs(d1[1:] - d1[:-1]) > thresh)\n",
    "\n",
    "    cond = sign_change & above_thresh\n",
    "    return cond.sum(axis=0)\n",
    "\n",
    "def var(x, axis=0):\n",
    "    \"\"\"Variance of EMG: another measure of signal power.\"\"\"\n",
    "    return x.var(axis=axis)\n",
    "\n",
    "def std(x, axis=0):\n",
    "    \"\"\"Standard Deviation: dispersion of signal amplitude.\"\"\"\n",
    "    return x.std(axis=axis)\n",
    "\n",
    "def iemg(x, axis=0):\n",
    "    \"\"\"Integrated EMG: sum of absolute values, often used in biomechanics.\"\"\"\n",
    "    return np.abs(x).sum(axis=axis)\n",
    "\n",
    "def kf(x, axis=0):\n",
    "    \"\"\"Kurtosis Factor: sensitive to outliers/spikes.\"\"\"\n",
    "    m = x.mean(axis=axis)\n",
    "    s = x.std(axis=axis)\n",
    "    return ((x - m)**4).mean(axis=axis) / (s**4 + 1e-8)\n",
    "\n",
    "def skewness(x, axis=0):\n",
    "    \"\"\"Skewness: measures asymmetry of amplitude distribution.\"\"\"\n",
    "    m = x.mean(axis=axis)\n",
    "    s = x.std(axis=axis)\n",
    "    return ((x - m)**3).mean(axis=axis) / (s**3 + 1e-8)\n",
    "\n",
    "def time_domain_feature_vector(seg):\n",
    "    \"\"\"\n",
    "    Compute a feature vector of common time-domain EMG features for one window.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    seg : np.ndarray\n",
    "        EMG window segment, shape (window_size, n_channels).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    feat : np.ndarray\n",
    "        1D feature vector (all features from all channels concatenated).\n",
    "    \"\"\"\n",
    "    # Basic power/amplitude measures\n",
    "    rms_val  = rms(seg, axis=0)      # Root Mean Square\n",
    "    mav_val  = mav(seg, axis=0)      # Mean Absolute Value\n",
    "    wl_val   = wl(seg, axis=0)       # Waveform Length\n",
    "    var_val  = var(seg, axis=0)      # Variance\n",
    "    std_val  = std(seg, axis=0)      # Standard Deviation\n",
    "    iemg_val = iemg(seg, axis=0)     # Integrated EMG\n",
    "    \n",
    "    # Signal complexity measures\n",
    "    zc_val   = zc(seg, axis=0)       # Zero Crossings\n",
    "    ssc_val  = ssc(seg, axis=0)      # Slope Sign Changes\n",
    "    \n",
    "    # Higher-order statistics\n",
    "    kurt_val = kf(seg, axis=0)       # Kurtosis Factor\n",
    "    skew_val = skewness(seg, axis=0) # Skewness\n",
    "    \n",
    "    # Concatenate all feature vectors (per channel) into one long vector\n",
    "    feat = np.concatenate([\n",
    "        rms_val, mav_val, wl_val, var_val, std_val, iemg_val,\n",
    "        zc_val, ssc_val, kurt_val, skew_val\n",
    "    ], axis=0)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421a96ce-08af-4cf4-a1d2-f0fc53f63ec0",
   "metadata": {},
   "source": [
    "# Frequency-Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e57b7bc-c446-40a1-b3be-37e9002f372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-12  # numerical stability\n",
    "\n",
    "def _welch_psd(x, fs, nperseg=None):\n",
    "    \"\"\"\n",
    "    Compute Welch PSD for each channel.\n",
    "    Args:\n",
    "        x: array (samples, channels)\n",
    "        fs: sampling rate (Hz)\n",
    "        nperseg: window length for Welch (samples). If None, auto-choose.\n",
    "    Returns:\n",
    "        f: frequencies (Hz) shape (F,)\n",
    "        Pxx: power spectral density (per channel) shape (F, C)\n",
    "    \"\"\"\n",
    "    if nperseg is None:\n",
    "        # Heuristic: clamp between 64 and 1024, but not longer than the signal\n",
    "        nperseg = int(np.clip(len(x), 64, 1024))\n",
    "    f, P = welch(x, fs=fs, nperseg=min(nperseg, len(x)), axis=0)  # P shape (F, C)\n",
    "    return f, P\n",
    "\n",
    "def total_power(x, fs):\n",
    "    \"\"\"Total power = integral of PSD across all freqs (per channel).\"\"\"\n",
    "    f, P = _welch_psd(x, fs)\n",
    "    # Trapz integrate across frequency for each channel\n",
    "    return np.trapezoid(P, f, axis=0)\n",
    "\n",
    "def bandpower(x, fs, band=(5, 15)):\n",
    "    \"\"\"\n",
    "    Band-limited power (per channel).\n",
    "    Args:\n",
    "        band: (f_low, f_high) in Hz\n",
    "    \"\"\"\n",
    "    f, P = _welch_psd(x, fs)\n",
    "    idx = (f >= band[0]) & (f <= band[1])\n",
    "    return np.trapezoid(P[idx, :], f[idx], axis=0)\n",
    "\n",
    "def mean_frequency(x, fs):\n",
    "    \"\"\"\n",
    "    Spectral mean frequency (a.k.a. spectral centroid).\n",
    "    sum(f * P) / sum(P) per channel.\n",
    "    \"\"\"\n",
    "    f, P = _welch_psd(x, fs)\n",
    "    denom = np.trapezoid(P, f, axis=0) + EPS\n",
    "    return np.trapezoid(P * f[:, None], f, axis=0) / denom\n",
    "\n",
    "def median_frequency(x, fs):\n",
    "    \"\"\"\n",
    "    Median frequency: frequency that splits total power into two equal halves.\n",
    "    \"\"\"\n",
    "    f, P = _welch_psd(x, fs)\n",
    "    # Normalize cumulative power per channel\n",
    "    cumsum = np.cumsum(P, axis=0)\n",
    "    # Total per channel\n",
    "    totals = cumsum[-1, :] + EPS\n",
    "    # Find the first frequency where cumulative power >= 50% of total\n",
    "    medf = np.empty(P.shape[1])\n",
    "    for c in range(P.shape[1]):\n",
    "        idx = np.searchsorted(cumsum[:, c], 0.5 * totals[c])\n",
    "        idx = np.clip(idx, 0, len(f) - 1)\n",
    "        medf[c] = f[idx]\n",
    "    return medf\n",
    "\n",
    "def peak_frequency(x, fs):\n",
    "    \"\"\"Frequency at which PSD is maximum (per channel).\"\"\"\n",
    "    f, P = _welch_psd(x, fs)\n",
    "    idx = np.argmax(P, axis=0)\n",
    "    return f[idx]\n",
    "\n",
    "def spectral_moments(x, fs, order=2):\n",
    "    \"\"\"\n",
    "    Spectral moments around the centroid:\n",
    "    - m0 = sum(P)               (total power)\n",
    "    - m1 = sum(f*P)/sum(P)      (mean freq / centroid)\n",
    "    - m2 = sum((f-m1)^2 * P)/sum(P)  (spectral variance / bandwidth^2)\n",
    "    Returns:\n",
    "        m0, m1, m2 â€” each (channels,)\n",
    "    \"\"\"\n",
    "    f, P = _welch_psd(x, fs)\n",
    "    m0 = np.trapezoid(P, f, axis=0) + EPS\n",
    "    m1 = np.trapezoid(P * f[:, None], f, axis=0) / m0\n",
    "    # variance around centroid\n",
    "    var = np.trapezoid(P * (f[:, None] - m1[None, :])**2, f, axis=0) / m0\n",
    "    return m0, m1, var\n",
    "\n",
    "def spectral_entropy(x, fs, base=2):\n",
    "    \"\"\"\n",
    "    Spectral entropy (Shannon) of normalized PSD (per channel).\n",
    "    Lower entropy -> more concentrated spectrum; higher -> more spread.\n",
    "    \"\"\"\n",
    "    f, P = _welch_psd(x, fs)\n",
    "    # Normalize PSD to a probability distribution across frequencies\n",
    "    Pn = P / (P.sum(axis=0, keepdims=True) + EPS)\n",
    "    H = -(Pn * np.log(Pn + EPS)).sum(axis=0)\n",
    "    if base == 2:\n",
    "        H = H / np.log(2)\n",
    "    return H\n",
    "\n",
    "def spectral_edge_frequency(x, fs, edge=0.95):\n",
    "    \"\"\"\n",
    "    Spectral edge frequency (SEF): the frequency below which `edge` (e.g., 95%)\n",
    "    of the total power is contained (per channel).\n",
    "    \"\"\"\n",
    "    f, P = _welch_psd(x, fs)\n",
    "    cum = np.cumsum(P, axis=0)\n",
    "    totals = cum[-1, :] + EPS\n",
    "    sef = np.empty(P.shape[1])\n",
    "    for c in range(P.shape[1]):\n",
    "        idx = np.searchsorted(cum[:, c], edge * totals[c])\n",
    "        idx = np.clip(idx, 0, len(f) - 1)\n",
    "        sef[c] = f[idx]\n",
    "    return sef\n",
    "\n",
    "def freq_domain_feature_vector(x, fs, bands=((5,15), (15,30))):\n",
    "    \"\"\"\n",
    "    Build a concatenated frequency-domain feature vector per channel.\n",
    "    Features included:\n",
    "      - total power\n",
    "      - bandpowers (for each band in `bands`)\n",
    "      - mean frequency\n",
    "      - median frequency\n",
    "      - peak frequency\n",
    "      - spectral variance (2nd central moment)\n",
    "      - spectral entropy\n",
    "      - SEF95 (edge=0.95)\n",
    "\n",
    "    Returns:\n",
    "        feat: array of shape (n_features * n_channels,)\n",
    "    \"\"\"\n",
    "    m0, m1, var = spectral_moments(x, fs)         # (C,) each\n",
    "    tp = m0                                       # total power\n",
    "    mf = m1                                       # mean/centroid\n",
    "    v  = var                                      # spectral variance\n",
    "    medf = median_frequency(x, fs)                # (C,)\n",
    "    peakf = peak_frequency(x, fs)                 # (C,)\n",
    "    sent = spectral_entropy(x, fs)                # (C,)\n",
    "    sef95 = spectral_edge_frequency(x, fs, 0.95)  # (C,)\n",
    "\n",
    "    # bandpowers per band\n",
    "    bp_list = [bandpower(x, fs, band=b) for b in bands]  # list of (C,)\n",
    "    # concatenate along feature dimension\n",
    "    feat_per_channel = np.vstack(\n",
    "        [tp, *(bp_list), mf, medf, peakf, v, sent, sef95]\n",
    "    )  # shape: (n_feat, C)\n",
    "    return feat_per_channel.ravel(order=\"F\")  # channel-major concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd151569-b5b8-4f75-a837-f35a0c0108fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature extraction config ---\n",
    "USE_TIME = True\n",
    "USE_FREQ = True\n",
    "FREQ_BANDS = ((5, 15), (15, 30))   # tweak for DB1 envelope; for DB2 you'd use higher bands\n",
    "\n",
    "def extract_feature_vector(seg, fs):\n",
    "    \"\"\"Return 1D feature vector for one window, based on toggles above.\"\"\"\n",
    "    feats = []\n",
    "    if USE_TIME:\n",
    "        feats.append(time_domain_feature_vector(seg))       # from earlier cell\n",
    "    if USE_FREQ:\n",
    "        feats.append(freq_domain_feature_vector(seg, fs, bands=FREQ_BANDS))  # from earlier cell\n",
    "    return np.concatenate(feats, axis=0) if len(feats) > 1 else feats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ed0322-abb5-4715-948a-68c5eabe89d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found .mat files: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "featureizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [28:27<00:00, 21.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1105889, 190),\n",
       " (1105889,),\n",
       " (1105889,),\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=int32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def subject_id_from_path(p):\n",
    "    \"\"\"Extract integer subject ID from filenames like S1_A1_E1.mat (case-insensitive).\"\"\"\n",
    "    m = re.search(r\"s(\\d+)\", p.stem.lower())\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "mats = sorted(DATA_RAW.rglob(\"*.mat\"))\n",
    "print(\"found .mat files:\", len(mats))\n",
    "assert mats, \"No .mat files found in data/raw/ninapro/db1\"\n",
    "\n",
    "# Limit for quick iteration (optional)\n",
    "MAX_FILES = None  # e.g., 10\n",
    "\n",
    "X_feat_list, Y_list = [], []\n",
    "SUBJ_list = []                              # NEW: collect subject id per window\n",
    "\n",
    "for p in tqdm(mats[:MAX_FILES], desc=\"featureizing\"):\n",
    "    d = read_mat(p)\n",
    "    emg = ensure_samples_channels(pick_key(d, \"emg\"))\n",
    "    y   = np.asarray(pick_key(d, \"restimulus\"), dtype=np.int32)\n",
    "\n",
    "    # Preprocess â†’ window\n",
    "    x_p = rectify_and_zscore(bandpass_filter(emg, fs=FS, low=1.0, high=40.0))\n",
    "    Xw, Yw = sliding_window(x_p, y, window_s=WINDOW_S, step_s=STEP_S, fs=FS)\n",
    "    if Xw.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    # Extract features per window\n",
    "    feats = np.vstack([extract_feature_vector(seg, FS) for seg in Xw])\n",
    "    X_feat_list.append(feats)\n",
    "    Y_list.append(Yw)\n",
    "\n",
    "    # NEW: tag each window with this file's subject id\n",
    "    sid = subject_id_from_path(p)\n",
    "    SUBJ_list.append(np.full(len(Yw), sid, dtype=np.int32))\n",
    "\n",
    "# Concatenate across files\n",
    "X_feat = np.vstack(X_feat_list) if X_feat_list else np.empty((0, ))\n",
    "Y      = np.concatenate(Y_list) if Y_list else np.empty((0, ), dtype=np.int32)\n",
    "SUBJ   = np.concatenate(SUBJ_list) if SUBJ_list else np.empty((0, ), dtype=np.int32)   # NEW\n",
    "\n",
    "# Optional: drop 'rest' windows (label==0) for gesture-only models\n",
    "mask = (Y != 0)\n",
    "Xf, Yf, Subjf = X_feat[mask], Y[mask], SUBJ[mask]         # CHANGED: keep subjects aligned\n",
    "\n",
    "# Save for reuse\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "np.save(DATA_PROCESSED / \"X_feat_db1.npy\", Xf)\n",
    "np.save(DATA_PROCESSED / \"y_db1.npy\",   Yf)\n",
    "np.save(DATA_PROCESSED / \"subjects_db1.npy\", Subjf)       # NEW\n",
    "\n",
    "Xf.shape, Yf.shape, Subjf.shape, np.unique(Subjf)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79236f65-2e3e-43f0-9891-f10f0f840ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
